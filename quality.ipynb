{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from helper.loader import load_ratings, load_movies, load_lists, load_500_1000_corr\n",
    "from helper.preprocesser import preprocess_ratings, prepare_test_data_dense\n",
    "from helper.application import application\n",
    "import helper.collaborative as coll\n",
    "import helper.showResults as sh\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance\n",
    "\n",
    "Notebook to check the performance of our different models by predicting ratings which we manually removed to have a ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = load_ratings()\n",
    "movies = load_movies()\n",
    "lists = load_lists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_new, lists_new = preprocess_ratings(ratings, lists, 500,1000)\n",
    "dense_user_item = coll.get_dense_user_item(ratings_new)\n",
    "popu_matrix = coll.get_popularity(lists_new, dense_user_item)\n",
    "\n",
    "average_ratings = coll.compute_average_ratings(dense_user_item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3188952"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dense_user_item.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "starting with only 1/1000 of data missing, this represent 3188 ratings to predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 8890.00it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label = prepare_test_data_dense(dense_user_item,1/300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense_user_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#key1,key2 = list(train_label.keys())[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dense_user_item.columns[key2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:07<00:00,  1.34it/s]\n"
     ]
    }
   ],
   "source": [
    "# Each removed ratings is for a new user -> will have to compute a lot of prediction, maybe something cleaner but didn't see\n",
    "\n",
    "classic_norm_SSE = 0\n",
    "classic_SSE = 0\n",
    "hybrid_norm_SSE = 0\n",
    "hybrid_SSE = 0\n",
    "pop_norm_SSE = 0\n",
    "pop_SSE = 0\n",
    "\n",
    "rounded_classic_norm_error = 0\n",
    "rounded_classic_error = 0\n",
    "rounded_hybrid_norm_error = 0\n",
    "rounded_hybrid_error = 0\n",
    "rounded_pop_norm_error = 0\n",
    "rounded_pop_error = 0\n",
    "\n",
    "\n",
    "for key1,key2 in tqdm(train_label.keys()):\n",
    "\n",
    "    user = train_data.index[key1]\n",
    "    item = train_data.columns[key2]\n",
    "\n",
    "    similarity = coll.get_k_dynamic_similar_users(train_data,user,40)\n",
    "    popularity = coll.get_k_popularity(popu_matrix,similarity)\n",
    "\n",
    "    ##################\n",
    "    weight_classic = similarity\n",
    "    \n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_classic,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_classic,train_data,average_ratings)\n",
    "\n",
    "    classic_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    classic_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_classic_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_classic_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    hybrid = similarity.loc[user] + popularity.loc[\"popularity\"]\n",
    "    weight_hybrid = hybrid.to_frame().transpose() \n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_hybrid,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_hybrid,train_data,average_ratings)\n",
    "\n",
    "    hybrid_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    hybrid_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_hybrid_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_hybrid_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    weight_pop = popularity\n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_pop,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_pop,train_data,average_ratings)\n",
    "        \n",
    "    pop_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    pop_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_pop_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_pop_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "    ##################\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For classical model: \n",
      "With normalization: average SSE = 0.20546733649878557, average rounded diff = 0.3\n",
      "Without normalization: average SSE = 0.18302398249376867, average rounded diff = 0.2\n",
      "For Hybrid model: \n",
      "With normalization: average SSE = 0.18888464924174314, average rounded diff = 0.3\n",
      "Without normalization: average SSE = 0.17094301720658348, average rounded diff = 0.2\n",
      "For Popularity only based model: \n",
      "With normalization: average SSE = 0.12329947094744798, average rounded diff = 0.2\n",
      "Without normalization: average SSE = 0.34396025560666804, average rounded diff = 0.4\n"
     ]
    }
   ],
   "source": [
    "nbr = len(train_label)\n",
    "\n",
    "print(\"For classical model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(classic_norm_SSE/nbr,rounded_classic_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(classic_SSE/nbr,rounded_classic_error/nbr))\n",
    "\n",
    "print(\"For Hybrid model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_norm_SSE/nbr,rounded_hybrid_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_SSE/nbr,rounded_hybrid_error/nbr))\n",
    "\n",
    "print(\"For Popularity only based model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(pop_norm_SSE/nbr,rounded_pop_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(pop_SSE/nbr,rounded_pop_error/nbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 30 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31/31 [00:00<00:00, 10900.69it/s]\n",
      "100%|██████████| 31/31 [00:24<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For classical model: \n",
      "With normalization: average SSE = 0.8581998990867361, average rounded diff = 0.7419354838709677\n",
      "Without normalization: average SSE = 1.1175007472736047, average rounded diff = 0.7741935483870968\n",
      "For Hybrid model: \n",
      "With normalization: average SSE = 0.8915128001507262, average rounded diff = 0.7741935483870968\n",
      "Without normalization: average SSE = 1.1264048736707912, average rounded diff = 0.8064516129032258\n",
      "For Popularity only based model: \n",
      "With normalization: average SSE = 1.0320785799561667, average rounded diff = 0.7419354838709677\n",
      "Without normalization: average SSE = 1.242506356928144, average rounded diff = 0.9032258064516129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label = prepare_test_data_dense(dense_user_item,1/100000)\n",
    "\n",
    "####################\n",
    "classic_norm_SSE = 0\n",
    "classic_SSE = 0\n",
    "hybrid_norm_SSE = 0\n",
    "hybrid_SSE = 0\n",
    "pop_norm_SSE = 0\n",
    "pop_SSE = 0\n",
    "\n",
    "rounded_classic_norm_error = 0\n",
    "rounded_classic_error = 0\n",
    "rounded_hybrid_norm_error = 0\n",
    "rounded_hybrid_error = 0\n",
    "rounded_pop_norm_error = 0\n",
    "rounded_pop_error = 0\n",
    "\n",
    "\n",
    "for key1,key2 in tqdm(train_label.keys()):\n",
    "\n",
    "    user = train_data.index[key1]\n",
    "    item = train_data.columns[key2]\n",
    "\n",
    "    similarity = coll.get_k_dynamic_similar_users(train_data,user,40)\n",
    "    popularity = coll.get_k_popularity(popu_matrix,similarity)\n",
    "\n",
    "    ##################\n",
    "    weight_classic = similarity\n",
    "    \n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_classic,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_classic,train_data,average_ratings)\n",
    "\n",
    "    classic_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    classic_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_classic_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_classic_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    hybrid = similarity.loc[user] + popularity.loc[\"popularity\"]\n",
    "    weight_hybrid = hybrid.to_frame().transpose() \n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_hybrid,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_hybrid,train_data,average_ratings)\n",
    "\n",
    "    hybrid_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    hybrid_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_hybrid_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_hybrid_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    weight_pop = popularity\n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_pop,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_pop,train_data,average_ratings)\n",
    "        \n",
    "    pop_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    pop_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_pop_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_pop_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "    ##################\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "nbr = len(train_label)\n",
    "\n",
    "print(\"For classical model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(classic_norm_SSE/nbr,rounded_classic_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(classic_SSE/nbr,rounded_classic_error/nbr))\n",
    "\n",
    "print(\"For Hybrid model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_norm_SSE/nbr,rounded_hybrid_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_SSE/nbr,rounded_hybrid_error/nbr))\n",
    "\n",
    "print(\"For Popularity only based model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(pop_norm_SSE/nbr,rounded_pop_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(pop_SSE/nbr,rounded_pop_error/nbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 300 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 318/318 [00:00<00:00, 12290.83it/s]\n",
      "100%|██████████| 318/318 [03:46<00:00,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For classical model: \n",
      "With normalization: average SSE = 0.7112991706439104, average rounded diff = 0.6540880503144654\n",
      "Without normalization: average SSE = 0.7927014635308044, average rounded diff = 0.6509433962264151\n",
      "For Hybrid model: \n",
      "With normalization: average SSE = 0.7178691268824478, average rounded diff = 0.6477987421383647\n",
      "Without normalization: average SSE = 0.804285097995739, average rounded diff = 0.6792452830188679\n",
      "For Popularity only based model: \n",
      "With normalization: average SSE = 0.939116679942665, average rounded diff = 0.7327044025157232\n",
      "Without normalization: average SSE = 1.0880041268901652, average rounded diff = 0.7830188679245284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label = prepare_test_data_dense(dense_user_item,1/10000)\n",
    "\n",
    "####################\n",
    "classic_norm_SSE = 0\n",
    "classic_SSE = 0\n",
    "hybrid_norm_SSE = 0\n",
    "hybrid_SSE = 0\n",
    "pop_norm_SSE = 0\n",
    "pop_SSE = 0\n",
    "\n",
    "rounded_classic_norm_error = 0\n",
    "rounded_classic_error = 0\n",
    "rounded_hybrid_norm_error = 0\n",
    "rounded_hybrid_error = 0\n",
    "rounded_pop_norm_error = 0\n",
    "rounded_pop_error = 0\n",
    "\n",
    "\n",
    "for key1,key2 in tqdm(train_label.keys()):\n",
    "\n",
    "    user = train_data.index[key1]\n",
    "    item = train_data.columns[key2]\n",
    "\n",
    "    similarity = coll.get_k_dynamic_similar_users(train_data,user,40)\n",
    "    popularity = coll.get_k_popularity(popu_matrix,similarity)\n",
    "\n",
    "    ##################\n",
    "    weight_classic = similarity\n",
    "    \n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_classic,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_classic,train_data,average_ratings)\n",
    "\n",
    "    classic_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    classic_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_classic_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_classic_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    hybrid = similarity.loc[user] + popularity.loc[\"popularity\"]\n",
    "    weight_hybrid = hybrid.to_frame().transpose() \n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_hybrid,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_hybrid,train_data,average_ratings)\n",
    "\n",
    "    hybrid_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    hybrid_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_hybrid_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_hybrid_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    weight_pop = popularity\n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_pop,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_pop,train_data,average_ratings)\n",
    "        \n",
    "    pop_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    pop_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_pop_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_pop_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "    ##################\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "nbr = len(train_label)\n",
    "\n",
    "print(\"For classical model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(classic_norm_SSE/nbr,rounded_classic_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(classic_SSE/nbr,rounded_classic_error/nbr))\n",
    "\n",
    "print(\"For Hybrid model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_norm_SSE/nbr,rounded_hybrid_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_SSE/nbr,rounded_hybrid_error/nbr))\n",
    "\n",
    "print(\"For Popularity only based model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(pop_norm_SSE/nbr,rounded_pop_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(pop_SSE/nbr,rounded_pop_error/nbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3'000 data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3188/3188 [00:00<00:00, 12980.09it/s]\n",
      "100%|██████████| 3188/3188 [37:11<00:00,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For classical model: \n",
      "With normalization: average SSE = 0.7031799656614639, average rounded diff = 0.6031994981179423\n",
      "Without normalization: average SSE = 0.7890107127694462, average rounded diff = 0.6558971141781681\n",
      "For Hybrid model: \n",
      "With normalization: average SSE = 0.7138551456235214, average rounded diff = 0.6126097867001254\n",
      "Without normalization: average SSE = 0.7997318753692487, average rounded diff = 0.6577791718946048\n",
      "For Popularity only based model: \n",
      "With normalization: average SSE = 0.909063123812653, average rounded diff = 0.6985570890840652\n",
      "Without normalization: average SSE = 1.042783065090846, average rounded diff = 0.7728983688833124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_data,train_label = prepare_test_data_dense(dense_user_item,1/1000)\n",
    "\n",
    "####################\n",
    "classic_norm_SSE = 0\n",
    "classic_SSE = 0\n",
    "hybrid_norm_SSE = 0\n",
    "hybrid_SSE = 0\n",
    "pop_norm_SSE = 0\n",
    "pop_SSE = 0\n",
    "\n",
    "rounded_classic_norm_error = 0\n",
    "rounded_classic_error = 0\n",
    "rounded_hybrid_norm_error = 0\n",
    "rounded_hybrid_error = 0\n",
    "rounded_pop_norm_error = 0\n",
    "rounded_pop_error = 0\n",
    "\n",
    "\n",
    "for key1,key2 in tqdm(train_label.keys()):\n",
    "\n",
    "    user = train_data.index[key1]\n",
    "    item = train_data.columns[key2]\n",
    "\n",
    "    similarity = coll.get_k_dynamic_similar_users(train_data,user,40)\n",
    "    popularity = coll.get_k_popularity(popu_matrix,similarity)\n",
    "\n",
    "    ##################\n",
    "    weight_classic = similarity\n",
    "    \n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_classic,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_classic,train_data,average_ratings)\n",
    "\n",
    "    classic_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    classic_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_classic_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_classic_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    hybrid = similarity.loc[user] + popularity.loc[\"popularity\"]\n",
    "    weight_hybrid = hybrid.to_frame().transpose() \n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_hybrid,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_hybrid,train_data,average_ratings)\n",
    "\n",
    "    hybrid_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    hybrid_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_hybrid_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_hybrid_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    weight_pop = popularity\n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_pop,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_pop,train_data,average_ratings)\n",
    "        \n",
    "    pop_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    pop_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_pop_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_pop_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "    ##################\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "nbr = len(train_label)\n",
    "\n",
    "print(\"For classical model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(classic_norm_SSE/nbr,rounded_classic_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(classic_SSE/nbr,rounded_classic_error/nbr))\n",
    "\n",
    "print(\"For Hybrid model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_norm_SSE/nbr,rounded_hybrid_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_SSE/nbr,rounded_hybrid_error/nbr))\n",
    "\n",
    "print(\"For Popularity only based model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(pop_norm_SSE/nbr,rounded_pop_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(pop_SSE/nbr,rounded_pop_error/nbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10'000 data missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 31889/31889 [00:02<00:00, 13398.20it/s]\n",
      " 45%|████▌     | 14486/31889 [2:47:41<3:21:27,  1.44it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/vincent/unifr/sp22/social_media/SMA_Project/quality.ipynb Cell 22'\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/sp22/social_media/SMA_Project/quality.ipynb#ch0000021vscode-remote?line=20'>21</a>\u001b[0m user \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mindex[key1]\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/sp22/social_media/SMA_Project/quality.ipynb#ch0000021vscode-remote?line=21'>22</a>\u001b[0m item \u001b[39m=\u001b[39m train_data\u001b[39m.\u001b[39mcolumns[key2]\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/sp22/social_media/SMA_Project/quality.ipynb#ch0000021vscode-remote?line=23'>24</a>\u001b[0m similarity \u001b[39m=\u001b[39m coll\u001b[39m.\u001b[39;49mget_k_dynamic_similar_users(train_data,user,\u001b[39m40\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/sp22/social_media/SMA_Project/quality.ipynb#ch0000021vscode-remote?line=24'>25</a>\u001b[0m popularity \u001b[39m=\u001b[39m coll\u001b[39m.\u001b[39mget_k_popularity(popu_matrix,similarity)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/vincent/unifr/sp22/social_media/SMA_Project/quality.ipynb#ch0000021vscode-remote?line=26'>27</a>\u001b[0m \u001b[39m##################\u001b[39;00m\n",
      "File \u001b[0;32m~/unifr/sp22/social_media/SMA_Project/helper/collaborative.py:88\u001b[0m, in \u001b[0;36mget_k_dynamic_similar_users\u001b[0;34m(user_item_matrix, user, K)\u001b[0m\n\u001b[1;32m     <a href='file:///home/vincent/unifr/sp22/social_media/SMA_Project/helper/collaborative.py?line=85'>86</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_k_dynamic_similar_users\u001b[39m(user_item_matrix: pd\u001b[39m.\u001b[39mDataFrame, user : \u001b[39mint\u001b[39m, K \u001b[39m=\u001b[39m \u001b[39m30\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m pd\u001b[39m.\u001b[39mDataFrame:\n\u001b[0;32m---> <a href='file:///home/vincent/unifr/sp22/social_media/SMA_Project/helper/collaborative.py?line=87'>88</a>\u001b[0m     correlation \u001b[39m=\u001b[39m user_item_matrix\u001b[39m.\u001b[39;49mcorrwith(user_item_matrix\u001b[39m.\u001b[39;49mloc[user],method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mpearson\u001b[39;49m\u001b[39m\"\u001b[39;49m,axis\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     <a href='file:///home/vincent/unifr/sp22/social_media/SMA_Project/helper/collaborative.py?line=89'>90</a>\u001b[0m     \u001b[39m#remove the correlation at one (either with itself or if suddenly one doesn't have any ratings anymore -> corr of one)\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/vincent/unifr/sp22/social_media/SMA_Project/helper/collaborative.py?line=90'>91</a>\u001b[0m     correlation[correlation \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.99\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py:9720\u001b[0m, in \u001b[0;36mDataFrame.corrwith\u001b[0;34m(self, other, axis, drop, method)\u001b[0m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9716'>9717</a>\u001b[0m this \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_numeric_data()\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9718'>9719</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Series):\n\u001b[0;32m-> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9719'>9720</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m this\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: other\u001b[39m.\u001b[39;49mcorr(x, method\u001b[39m=\u001b[39;49mmethod), axis\u001b[39m=\u001b[39;49maxis)\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9721'>9722</a>\u001b[0m other \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39m_get_numeric_data()\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9722'>9723</a>\u001b[0m left, right \u001b[39m=\u001b[39m this\u001b[39m.\u001b[39malign(other, join\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py:8833\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=8821'>8822</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mapply\u001b[39;00m \u001b[39mimport\u001b[39;00m frame_apply\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=8823'>8824</a>\u001b[0m op \u001b[39m=\u001b[39m frame_apply(\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=8824'>8825</a>\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=8825'>8826</a>\u001b[0m     func\u001b[39m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=8830'>8831</a>\u001b[0m     kwargs\u001b[39m=\u001b[39mkwargs,\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=8831'>8832</a>\u001b[0m )\n\u001b[0;32m-> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=8832'>8833</a>\u001b[0m \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39;49mapply()\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mapply\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py:727\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=723'>724</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw:\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=724'>725</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_raw()\n\u001b[0;32m--> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=726'>727</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py:851\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=849'>850</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply_standard\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m--> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=850'>851</a>\u001b[0m     results, res_index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_series_generator()\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=852'>853</a>\u001b[0m     \u001b[39m# wrap results\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=853'>854</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwrap_results(results, res_index)\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py:867\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=863'>864</a>\u001b[0m \u001b[39mwith\u001b[39;00m option_context(\u001b[39m\"\u001b[39m\u001b[39mmode.chained_assignment\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=864'>865</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i, v \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(series_gen):\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=865'>866</a>\u001b[0m         \u001b[39m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m--> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=866'>867</a>\u001b[0m         results[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(v)\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=867'>868</a>\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=868'>869</a>\u001b[0m             \u001b[39m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=869'>870</a>\u001b[0m             \u001b[39m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m    <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/apply.py?line=870'>871</a>\u001b[0m             results[i] \u001b[39m=\u001b[39m results[i]\u001b[39m.\u001b[39mcopy(deep\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py:9720\u001b[0m, in \u001b[0;36mDataFrame.corrwith.<locals>.<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9716'>9717</a>\u001b[0m this \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_numeric_data()\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9718'>9719</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(other, Series):\n\u001b[0;32m-> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9719'>9720</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m this\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: other\u001b[39m.\u001b[39;49mcorr(x, method\u001b[39m=\u001b[39;49mmethod), axis\u001b[39m=\u001b[39maxis)\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9721'>9722</a>\u001b[0m other \u001b[39m=\u001b[39m other\u001b[39m.\u001b[39m_get_numeric_data()\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/frame.py?line=9722'>9723</a>\u001b[0m left, right \u001b[39m=\u001b[39m this\u001b[39m.\u001b[39malign(other, join\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minner\u001b[39m\u001b[39m\"\u001b[39m, copy\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py:2557\u001b[0m, in \u001b[0;36mSeries.corr\u001b[0;34m(self, other, method, min_periods)\u001b[0m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2553'>2554</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2555'>2556</a>\u001b[0m \u001b[39mif\u001b[39;00m method \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mspearman\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mkendall\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39mor\u001b[39;00m callable(method):\n\u001b[0;32m-> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2556'>2557</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m nanops\u001b[39m.\u001b[39;49mnancorr(\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2557'>2558</a>\u001b[0m         this\u001b[39m.\u001b[39;49mvalues, other\u001b[39m.\u001b[39;49mvalues, method\u001b[39m=\u001b[39;49mmethod, min_periods\u001b[39m=\u001b[39;49mmin_periods\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2558'>2559</a>\u001b[0m     )\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2560'>2561</a>\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2561'>2562</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmethod must be either \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpearson\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2562'>2563</a>\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mspearman\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39mkendall\u001b[39m\u001b[39m'\u001b[39m\u001b[39m, or a callable, \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2563'>2564</a>\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mmethod\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m was supplied\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/series.py?line=2564'>2565</a>\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py:93\u001b[0m, in \u001b[0;36mdisallow.__call__.<locals>._f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=90'>91</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=91'>92</a>\u001b[0m     \u001b[39mwith\u001b[39;00m np\u001b[39m.\u001b[39merrstate(invalid\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m---> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=92'>93</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m f(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=93'>94</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=94'>95</a>\u001b[0m     \u001b[39m# we want to transform an object array\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=95'>96</a>\u001b[0m     \u001b[39m# ValueError message to the more typical TypeError\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=96'>97</a>\u001b[0m     \u001b[39m# e.g. this is normally a disallowed function on\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=97'>98</a>\u001b[0m     \u001b[39m# object arrays that contain strings\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=98'>99</a>\u001b[0m     \u001b[39mif\u001b[39;00m is_object_dtype(args[\u001b[39m0\u001b[39m]):\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py:1546\u001b[0m, in \u001b[0;36mnancorr\u001b[0;34m(a, b, method, min_periods)\u001b[0m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=1542'>1543</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mnan\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=1544'>1545</a>\u001b[0m f \u001b[39m=\u001b[39m get_corr_func(method)\n\u001b[0;32m-> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=1545'>1546</a>\u001b[0m \u001b[39mreturn\u001b[39;00m f(a, b)\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py:1567\u001b[0m, in \u001b[0;36mget_corr_func.<locals>.func\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=1565'>1566</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfunc\u001b[39m(a, b):\n\u001b[0;32m-> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/pandas/core/nanops.py?line=1566'>1567</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39;49mcorrcoef(a, b)[\u001b[39m0\u001b[39m, \u001b[39m1\u001b[39m]\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py:2683\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2678'>2679</a>\u001b[0m \u001b[39mif\u001b[39;00m bias \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue \u001b[39mor\u001b[39;00m ddof \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39m_NoValue:\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2679'>2680</a>\u001b[0m     \u001b[39m# 2015-03-15, 1.10\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2680'>2681</a>\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\u001b[39m'\u001b[39m\u001b[39mbias and ddof have no effect and are deprecated\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2681'>2682</a>\u001b[0m                   \u001b[39mDeprecationWarning\u001b[39;00m, stacklevel\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m-> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2682'>2683</a>\u001b[0m c \u001b[39m=\u001b[39m cov(x, y, rowvar, dtype\u001b[39m=\u001b[39;49mdtype)\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2683'>2684</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2684'>2685</a>\u001b[0m     d \u001b[39m=\u001b[39m diag(c)\n",
      "File \u001b[0;32m<__array_function__ internals>:5\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py:2453\u001b[0m, in \u001b[0;36mcov\u001b[0;34m(m, y, rowvar, bias, ddof, fweights, aweights, dtype)\u001b[0m\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2448'>2449</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2449'>2450</a>\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mddof must be integer\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2451'>2452</a>\u001b[0m \u001b[39m# Handles complex arrays too\u001b[39;00m\n\u001b[0;32m-> <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2452'>2453</a>\u001b[0m m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49masarray(m)\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2453'>2454</a>\u001b[0m \u001b[39mif\u001b[39;00m m\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m   <a href='file:///home/vincent/miniconda3/envs/social/lib/python3.9/site-packages/numpy/lib/function_base.py?line=2454'>2455</a>\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mm has more than 2 dimensions\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_data,train_label = prepare_test_data_dense(dense_user_item,1/300)\n",
    "\n",
    "####################\n",
    "classic_norm_SSE = 0\n",
    "classic_SSE = 0\n",
    "hybrid_norm_SSE = 0\n",
    "hybrid_SSE = 0\n",
    "pop_norm_SSE = 0\n",
    "pop_SSE = 0\n",
    "\n",
    "rounded_classic_norm_error = 0\n",
    "rounded_classic_error = 0\n",
    "rounded_hybrid_norm_error = 0\n",
    "rounded_hybrid_error = 0\n",
    "rounded_pop_norm_error = 0\n",
    "rounded_pop_error = 0\n",
    "\n",
    "\n",
    "for key1,key2 in tqdm(train_label.keys()):\n",
    "\n",
    "    user = train_data.index[key1]\n",
    "    item = train_data.columns[key2]\n",
    "\n",
    "    similarity = coll.get_k_dynamic_similar_users(train_data,user,40)\n",
    "    popularity = coll.get_k_popularity(popu_matrix,similarity)\n",
    "\n",
    "    ##################\n",
    "    weight_classic = similarity\n",
    "    \n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_classic,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_classic,train_data,average_ratings)\n",
    "\n",
    "    classic_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    classic_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_classic_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_classic_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    hybrid = similarity.loc[user] + popularity.loc[\"popularity\"]\n",
    "    weight_hybrid = hybrid.to_frame().transpose() \n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_hybrid,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_hybrid,train_data,average_ratings)\n",
    "\n",
    "    hybrid_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    hybrid_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_hybrid_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_hybrid_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "\n",
    "    ##################\n",
    "    weight_pop = popularity\n",
    "\n",
    "    pred_norm = coll.predict_value_norm(user,item,weight_pop,train_data,average_ratings)\n",
    "    pred = coll.predict_value(user,item,weight_pop,train_data,average_ratings)\n",
    "        \n",
    "    pop_norm_SSE += (pred_norm - train_label[(key1,key2)])**2\n",
    "    pop_SSE += (pred - train_label[(key1,key2)])**2\n",
    "\n",
    "    rounded_pop_norm_error += abs(round(pred_norm) - train_label[(key1,key2)])\n",
    "    rounded_pop_error += abs(round(pred) - train_label[(key1,key2)])\n",
    "    ##################\n",
    "\n",
    "\n",
    "\n",
    "##################################\n",
    "nbr = len(train_label)\n",
    "\n",
    "print(\"For classical model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(classic_norm_SSE/nbr,rounded_classic_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(classic_SSE/nbr,rounded_classic_error/nbr))\n",
    "\n",
    "print(\"For Hybrid model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_norm_SSE/nbr,rounded_hybrid_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(hybrid_SSE/nbr,rounded_hybrid_error/nbr))\n",
    "\n",
    "print(\"For Popularity only based model: \")\n",
    "print(\"With normalization: average SSE = {}, average rounded diff = {}\".format(pop_norm_SSE/nbr,rounded_pop_norm_error/nbr))\n",
    "print(\"Without normalization: average SSE = {}, average rounded diff = {}\".format(pop_SSE/nbr,rounded_pop_error/nbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting everything for 10 removed ratings just to see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 9414.82it/s]\n"
     ]
    }
   ],
   "source": [
    "train_data_2,train_label_2 = prepare_test_data_dense(dense_user_item,1/300000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For user 70929901 and movie 2083, the true ratings was 4.0\n",
      "The classical model predicted 4.366124772998244 with normalization and 4.08230020935102 without\n",
      "The hybrid model predicted 4.334833886793348 with normalization and 4.036882293536396 without\n",
      "The popularity model predicted 3.4741589719285715 with normalization and 2.7876348107032083 without\n",
      "################################\n",
      "For user 10040458 and movie 402, the true ratings was 4.0\n",
      "The classical model predicted 5 with normalization and 4.237505533225593 without\n",
      "The hybrid model predicted 4.889349607306551 with normalization and 4.234722687670517 without\n",
      "The popularity model predicted 4.579815126019368 with normalization and 4.227625664078463 without\n",
      "################################\n",
      "For user 33246005 and movie 4124, the true ratings was 3.0\n",
      "The classical model predicted 2.2888367633349596 with normalization and 2.584491556826118 without\n",
      "The hybrid model predicted 2.2888367633349596 with normalization and 2.584491556826118 without\n",
      "The popularity model predicted 3.210059171597633 with normalization and 3.210059171597633 without\n",
      "################################\n",
      "For user 72658609 and movie 1898, the true ratings was 4.0\n",
      "The classical model predicted 3.744142624784343 with normalization and 3.334468488942111 without\n",
      "The hybrid model predicted 3.5913152156644474 with normalization and 3.166705781528962 without\n",
      "The popularity model predicted 3.0229566498614595 with normalization and 2.5428034833112343 without\n",
      "################################\n",
      "For user 57608812 and movie 484, the true ratings was 4.0\n",
      "The classical model predicted 3.6230829745108615 with normalization and 4.429650213531347 without\n",
      "The hybrid model predicted 3.6229883697950767 with normalization and 4.392579387545019 without\n",
      "The popularity model predicted 3.622674836031536 with normalization and 4.269721288002398 without\n",
      "################################\n",
      "For user 66919492 and movie 18458, the true ratings was 2.0\n",
      "The classical model predicted 3.630698512831744 with normalization and 3.089474286642055 without\n",
      "The hybrid model predicted 3.6187455358587 with normalization and 3.068835692687787 without\n",
      "The popularity model predicted 3.4740938194984583 with normalization and 2.8190729728666373 without\n",
      "################################\n",
      "For user 96698926 and movie 3369, the true ratings was 1.0\n",
      "The classical model predicted 2.242869953684625 with normalization and 2.150068554800779 without\n",
      "The hybrid model predicted 2.1764017201052344 with normalization and 2.078081817836586 without\n",
      "The popularity model predicted 1.7154856163363794 with normalization and 1.5788983050847458 without\n",
      "################################\n",
      "For user 55327630 and movie 2092, the true ratings was 5.0\n",
      "The classical model predicted 5 with normalization and 4.71743110766274 without\n",
      "The hybrid model predicted 5 with normalization and 4.721366316362284 without\n",
      "The popularity model predicted 5 with normalization and 5.0 without\n",
      "################################\n",
      "For user 15720652 and movie 1299, the true ratings was 5.0\n",
      "The classical model predicted 5 with normalization and 4.497475426280832 without\n",
      "The hybrid model predicted 5 with normalization and 4.386588285109926 without\n",
      "The popularity model predicted 4.964112679955703 with normalization and 4.0 without\n",
      "################################\n",
      "For user 5627368 and movie 399, the true ratings was 5.0\n",
      "The classical model predicted 4.132060478672064 with normalization and 3.993119980463581 without\n",
      "The hybrid model predicted 3.9420767092704345 with normalization and 3.7804696497912276 without\n",
      "The popularity model predicted 3.470977469294541 with normalization and 3.2531645569620253 without\n",
      "################################\n"
     ]
    }
   ],
   "source": [
    "for key1,key2 in train_label_2.keys():\n",
    "\n",
    "    user = train_data_2.index[key1]\n",
    "    item = train_data_2.columns[key2]\n",
    "\n",
    "    similarity = coll.get_k_dynamic_similar_users(train_data_2,user,40)\n",
    "    popularity = coll.get_k_popularity(popu_matrix,similarity)\n",
    "\n",
    "    ##################\n",
    "    weight_classic = similarity\n",
    "    \n",
    "    cla_pred_norm = coll.predict_value_norm(user,item,weight_classic,train_data_2,average_ratings)\n",
    "    cla_pred = coll.predict_value(user,item,weight_classic,train_data_2,average_ratings)\n",
    "\n",
    "    ##################\n",
    "    hybrid = similarity.loc[user] + popularity.loc[\"popularity\"]\n",
    "    weight_hybrid = hybrid.to_frame().transpose() \n",
    "\n",
    "    hyb_pred_norm = coll.predict_value_norm(user,item,weight_hybrid,train_data_2,average_ratings)\n",
    "    hyb_pred = coll.predict_value(user,item,weight_hybrid,train_data_2,average_ratings)\n",
    "\n",
    "    ##################\n",
    "    weight_pop = popularity\n",
    "\n",
    "    pop_pred_norm = coll.predict_value_norm(user,item,weight_pop,train_data_2,average_ratings)\n",
    "    pop_pred = coll.predict_value(user,item,weight_pop,train_data_2,average_ratings)\n",
    "    ##################\n",
    "\n",
    "    print(\"For user {} and movie {}, the true ratings was {}\".format(user,item,train_label_2[(key1,key2)]))\n",
    "    print(\"The classical model predicted {} with normalization and {} without\".format(cla_pred_norm,cla_pred))\n",
    "    print(\"The hybrid model predicted {} with normalization and {} without\".format(hyb_pred_norm,hyb_pred))\n",
    "    print(\"The popularity model predicted {} with normalization and {} without\".format(pop_pred_norm,pop_pred))\n",
    "    print(\"################################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "903e7e2862ff4215d6e17c2a7262d9cc840f26402d44e286ed2eb13102c7459e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('social')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
